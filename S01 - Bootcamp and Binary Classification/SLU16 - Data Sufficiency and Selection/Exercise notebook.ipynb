{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acae99ed9fc3040b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SLU16 - Data Sufficiency and Selection\n",
    "### Exercise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43c2ce08e77f6c4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from utils import plot_learning_curve\n",
    "import inspect\n",
    "\n",
    "from hashlib import sha1 # just for grading purposes\n",
    "import json\n",
    "\n",
    "def _hash(obj):\n",
    "    if type(obj) is not str:\n",
    "        obj = json.dumps(obj)\n",
    "    return sha1(obj.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-94483f723ebdd165",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Context \n",
    "As you've learned, it's very important that the data scientist has a good domain knowledge of the field where they are working in, so that they can recognize unexpected effects, and can use their world model to chose features. \n",
    "\n",
    "So... to make sure we're all on the same level going into the exercises, we're going to be distinguishing between young and adult Abalones. \n",
    "\n",
    "What are Abalones, you ask? These cool things: \n",
    "![](https://nnimgt-a.akamaihd.net/transform/v1/crop/frm/Jesinta.Burton/30bc51dc-c571-4944-8dff-a7b5d0c14ff4.jpg/r0_0_728_409_w1200_h678_fmax.jpg)\n",
    "\n",
    "For reasons which are frankly beyond me, there are people who know a lot about detecting the age of abalones. \n",
    "\n",
    "You will do this with machine learning. \n",
    "\n",
    "To make matters worse, your instructor is evil, and has added nonsensical random features. \n",
    "\n",
    "### Data\n",
    "The target is `adult`, and is 0 when the abalone is a child, 1 when it's an adult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0839bde5b14baf77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/abalone.csv')\n",
    "df = pd.get_dummies(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42ed57216c607b39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Exercise 1 - find the nonsense \n",
    "\n",
    "There are 3 features which are just random. Without using any model, find out which ones they are. \n",
    "\n",
    "To determine this use\n",
    "1. pearson correlation \n",
    "2. mutual information (`mutual_info_classif`)\n",
    "\n",
    "We don't really care about the intermediate steps, but you should probably visualize these in whatever way you like.  \n",
    "\n",
    "_Hint #1: you can use `display(<something>)` if you want to force jupyter to display a series_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-673bad1efe00da17",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# X = ... \n",
    "# y = ... \n",
    "\n",
    "# pearson_corr = ...\n",
    "# something something \n",
    "\n",
    "# mutual_info = ... \n",
    "# something something \n",
    "\n",
    "# nonsense_features = [first, second, third]  (feature names only, the order does not matter)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1c7c23daa266bdb8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(sorted(nonsense_features)) == '1f2779dbe1c037234cba7a7f7f303bee81757cc1'\n",
    "print('Great success!')\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - observe the tree \n",
    "\n",
    "Yay! Time to look at trees. \n",
    "\n",
    "To pass this exercise, you will make a function called `train_and_plot_tree` that will do the following: \n",
    "\n",
    "1. Fit a tree with `max_depth` of 3, and `min_samples_split` of 20 \n",
    "2. Plot that tree, in a way that clearly shows the feature names, and the percentage of adults in each node. \n",
    "3. Return the plot (just assign the output of a function to a variable and return it for evaluation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f977294d9f7221d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_plot_tree(X, y): \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    return my_plot \n",
    "\n",
    "\n",
    "tree_plot = train_and_plot_tree(X, y);\n",
    "tree_plot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7775d77d44ce34a5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sig = inspect.signature(train_and_plot_tree)\n",
    "assert set(sig.parameters.keys()) == {'X', 'y'}, 'Do not change the signature!'  \n",
    "all_text = ''.join([tree_plot[i].get_text() for i in range(len(tree_plot))])\n",
    "assert 'Shell weight' in all_text, 'Your feature names seem weird'\n",
    "assert 'child' in all_text, 'Did you make the right labels for class names?'\n",
    "first_node_feature = tree_plot[0].get_text().split('<')[0].strip()\n",
    "assert _hash(first_node_feature) == 'a0a91ccd0f0074dd419b7750263b9fbe107e7c86', 'Unexpected first node'\n",
    "assert len(tree_plot) == 15, 'The tree seems to have the wrong size'\n",
    "node_12 = tree_plot[12].get_text()\n",
    "assert 'gini = 0.028' in node_12, 'Are you sure you configured the tree correctly?'\n",
    "assert 'adult' in node_12, 'We want you to have the target labels in the plot'\n",
    "assert '0.986' in node_12, 'Do you have the proportions in the nodes?'\n",
    "print('Great success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de46d410dc20243a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 3: model based feature importances (linear) \n",
    "You will fit a logistic regression to get the features that produce the top 5 coefficients. \n",
    "Note that the coefficients can be both positive and negative, and you care about \"the biggest magnitude\". \n",
    "\n",
    "We will take care of the normalization for you. _(if you ever train a logistic regression without normalizing the features I will place gummybears in your lasagna. Consider yourself warned.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc19094b56d9ac01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rs = RobustScaler()  # just scaling, because I'm nice. \n",
    "X_normed = pd.DataFrame(rs.fit_transform(X), \n",
    "                        columns=X.columns)  # remember this? cool huh! \n",
    "\n",
    "\n",
    "# As before, we just want the names of the features, in a list. \n",
    "# From now it's up to you. Use default parameters on the logistic regression. \n",
    "# something (~ 5 rows) \n",
    "# top_5_by_magnitude_linear = ... \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(sorted(top_5_by_magnitude_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b9a38bc2ecd14fa6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(top_5_by_magnitude_linear) == 5 \n",
    "assert _hash(sorted(top_5_by_magnitude_linear)) == 'f814d06f92beab782a3d1e0d0d9fe3098520c2b2'\n",
    "print('Great success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-50658e68c72b4705",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 4: model based feature importances (non-linear) \n",
    "Oh, you made it! Good. Now for non-linear. \n",
    "\n",
    "Train a Random Forest, with the following parameters: \n",
    "* n_estimators = 50 \n",
    "* max_depth = 2\n",
    "* min_samples_split = 50 \n",
    "* random_state = 1000\n",
    "* n_jobs = -1  (optional, but speeds things up)\n",
    "\n",
    "Then use it to get feature importances. Use the non-normalized features. \n",
    "\n",
    "As before, get the top 5 features by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-449d3986efce770b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# rf = ... \n",
    "\n",
    "# something (~5 rows)\n",
    "\n",
    "# top_5_by_importance_random_forest = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(sorted(top_5_by_importance_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-573689d4cf79b527",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(top_5_by_importance_random_forest) == 5\n",
    "assert _hash(sorted(top_5_by_importance_random_forest)) == 'bbc12adaef06b61e02cb766182fab945577633b4'\n",
    "print('Great success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cb8cb57f3b345642",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 5: \n",
    "\n",
    "Do we have enough data, or should we go collect more abalones? Let's find out with learning curves! \n",
    "\n",
    "Using the random forest you already initialized, do the following: \n",
    "\n",
    "1. Define a numpy array of train_sizes, from 10% of the data to 100%, in increments of 10% (0.1, 0.2, 0.3... etc) \n",
    "\n",
    "\n",
    "2. Get the learning curve data, with the following configuration:\n",
    "    - classifier: your old random forest from exercise 4 \n",
    "    - metric: use area under the roc curve as your metric \n",
    "    - use the train sizes array you just created\n",
    "    - all features, not normalized \n",
    "    - cv = 5 \n",
    "    - random state = 1000 (needed to pass the grader) \n",
    "    - n_jobs = -1 (optional, but faster) \n",
    "\n",
    "As with the learning notebooks you should save the output to `train_sizes_abs`, `train_scores` and `test_scores` \n",
    "\n",
    "3. Plot it! _(feel free to use plot_learning_curve that we used in the learning notebook, but remember that's custom code)_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f920f407c20e79d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train_sizes = ...   (10% increments, starting at 10%)\n",
    "# train_sizes_abs, train_scores, test_scores (get the data, no plotting here)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-34319b98d5b377f6",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "e1 = 'your train scores dont look right. Did you use the right features? Maybe check for categoricals, that can cause issues'\n",
    "assert np.nan not in train_scores, e1 \n",
    "assert train_sizes.sum() == 5.5, 'Are your train sizes correct?'\n",
    "assert train_sizes.mean() == .55, 'Are your train sizes correct?'\n",
    "assert len(train_sizes) == 10, 'Are your train sizes correct?'\n",
    "assert train_sizes_abs.mean() == 1837.1, 'Are your train sizes abs correct?'\n",
    "assert round(pd.DataFrame(train_scores).mean().median(), 2) == 0.94, 'Are your train scores correct?'\n",
    "assert round(pd.DataFrame(test_scores).median().quantile(.3), 2) == 0.93, 'Are your test scores correct?'\n",
    "print('Great success!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU14 - k-Nearest Neighbours (kNN)\n",
    "\n",
    "In this notebook we will be covering the following:\n",
    "\n",
    "- k-Nearest Neighbours Algorithm\n",
    "- A Primer on Distance\n",
    "- Some considerations about kNN\n",
    "- Using kNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. k-Nearest Neighbours Algorithm\n",
    "\n",
    "k-Nearest Neighbours (or kNN) is a supervised learning algorithm, that is mainly used for classification, but can also be used for regression tasks.\n",
    "\n",
    "Its main advantages are that it is very simple to understand and implement (as you'll see here!) and that it can be used in a wide range of problems.\n",
    "\n",
    "Its main disadvantages are that it doesn't scale very well to large datasets and to high dimensional spaces (without some optimisations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 How does it work\n",
    "\n",
    "The main intuition behind the algorithm is that neighbors are similar to each other. \n",
    "\n",
    "For example, a cat is likely to be more similar to other cats than to a dog. \n",
    "\n",
    "And if we want to classify whether it's a cat or a dog based on some parameters (e.g., sharpness of claws and length of ears), we can take a look on a few most similar neighbors and see whether they are dogs or cats.\n",
    "\n",
    "If 4 out of 5 most similar animals are cats, it's very likely that this one is a cat too, right?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic](media/cats_dogs_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, the principle behind k-nearest neighbour methods is to find a predefined number of training samples closest to the point we want to find a prediction for, and predict the label from these. The predifined number of samples is a user-defined constant `k`.\n",
    "\n",
    "In the example above, we decided to take a look on the 5 most similar animals, so `k` was 5.\n",
    "\n",
    "The assumption here is that if two points are similar, i.e, close together in the features space, then their labels should also be similar.\n",
    "\n",
    "We'll be more careful in the definition of similarity, but let's first begin with one more example on how can we use kNN for classification and another for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic](media/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **Classification with kNN** figure, we can see how kNN can be used for classification.\n",
    "\n",
    "We have a point for which we want to predict a class, in this case it's the yellow star. We start by finding the _k_ points in the training data that are the closest to the star: these are the k-nearest neighbours. Then, we select as the predicted class for the star, the most common class among the k-nearest neighbours.\n",
    "\n",
    "In this example above, if we use _k_ = _3_, the star's nearest neighbours are the two red circles and the blue square that are inside the smallest dashed circle. The most common class among the nearest neighbours is class B (red circles), so that is the class that we'll predict for the star. \n",
    "\n",
    "Can you figure out what would be the predicted class if we used _k_ = _7_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might ask a reasonable question: what if k=4 and we have 2 red circles and 2 blue squares out of 4 nearest neighbors?\n",
    "\n",
    "Well, for binary classification we're usually trying to select odd values for k. It solves the problem completely: one of the classes will always appear at least 1 more time than the other one.\n",
    "\n",
    "But it's not only a case when k is even. For 3-classes classification (e.g. cats, dogs and parrots) we might have k=5, and out of 5 nearest neighbors there might be 2 cats, 2 dogs and 1 parrot. \n",
    "\n",
    "In this case the algorithms usually select one of 2 options: \n",
    "\n",
    "1. Choose a random class (cat or dog)\n",
    "2. Choose the one that has the lowest average distance: if 2 cats are nearer than 2 dogs, the label is cat.\n",
    "\n",
    "We're not going to implement this corner case, but keep it in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **Regression with kNN** figure, we can see how kNN can be used for regression.\n",
    "\n",
    "We have a point for which we know the x-value and want to predict the y-value (which is the star!). Again we need to find the k-nearest neighbours, and then, select as the predicted value, **the average y-value of the k-nearest neighbours.**\n",
    "\n",
    "In this example above, we know the star's x-value, which is 8, and we want to predict its y-value.\n",
    "If we use _k_ = _3_, the star's nearest neighbours (measured in the x-axis) are the three points within the shaded area. \n",
    "To get the predicted y-value for the star, we average the y-values of the nearest neighbours:\n",
    "\n",
    "$$\\frac{2+4+5}{3} = 3.67$$\n",
    "\n",
    "Can you figure out what would be the predicted y-value for the star if we used _k_ = _5_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Primer on Distance\n",
    "\n",
    "As we mentioned before, in order to find the k-nearest neighbours of a point, we need to have a measure of similarity, in order to actually understand how \"near\" two points are.\n",
    "\n",
    "The most common way to handle this is to use a **distance function**, that gives us a numerical measurement of how far apart two points are. Once we have such a function, we can select the nearest neighbours of a certain point by finding the neighbours for which the distance is the smallest.\n",
    "\n",
    "In most of the cases, using a distance function to measure distances between data points requires all the features in a dataset to be numerical. So, in case you have any categorical variables, you will need to represent them as numbers (or drop them!), before measuring distances in your dataset.\n",
    "\n",
    "Let's see some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Euclidean distance\n",
    "\n",
    "Remeber when you were in high school and had to compute vector norms and distances between vectors? Cool, because you were using the Euclidean distance back then!\n",
    "\n",
    "Let's define it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The one dimensional case**\n",
    "\n",
    "In the one dimensional case, we have two one-dimensional points **p** and **q**.\n",
    "\n",
    "$$d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{(q - p)^2} = |q - p|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The two dimensional case**\n",
    "\n",
    "In the two dimensional case, we have two two-dimensional points or vectors $\\mathbf{p}$ and $\\mathbf{q}$.\n",
    "\n",
    "$$d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The n dimensional case**\n",
    "\n",
    "In the n dimensional case, we have two n-dimensional points or vectors $\\mathbf{p}$ and $\\mathbf{q}$.\n",
    "\n",
    "$$d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2 + ... + (q_n - p_n)^2} = \\sqrt{ \\sum_{i=1}^n (q_i - p_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The euclidean distance is a good choice when the features are more or less in the same range of values. Can you figure out why this is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dot product (*)\n",
    "\n",
    "The dot product between two n-dimensional vectors $\\mathbf{u}$ and $\\mathbf{v}$ is defined as\n",
    "\n",
    "$$\\mathbf{u} \\; .  \\mathbf{v} = \\sum_{i=1}^n u_i v_i = u_1v_1 + u_2v_2 + ... + u_nv_n$$\n",
    "\n",
    "Given the angle formed by the two vectors, $\\theta$, and the norms of the vectors $|.|$, we can also define the dot product between $\\mathbf{u}$ and $\\mathbf{v}$ as\n",
    "\n",
    "$$\\mathbf{u} \\; .  \\mathbf{v} = |\\mathbf{u}| \\; |\\mathbf{v}| \\; cos(\\theta)$$\n",
    "\n",
    "\n",
    "In fact, this second definition makes it easier to understand how the dot product can be used as a distance.\n",
    "The dot product measures the projection of one vector into the other, which basically means that we're measuring the vectors' norms and how much the two vectors are pointing in the same direction.\n",
    "\n",
    "**Note:** $\\theta$ is the angle between vectors $\\mathbf{u}$ and $\\mathbf{v}$, so $cos(\\theta) = cos(\\mathbf{u}, \\mathbf{v})$\n",
    "\n",
    "Let's use the following image and consider some particular cases to get a better intuition on this.\n",
    "\n",
    "![pic](media/dot_product.png)\n",
    "\n",
    "This image shows a representation of the dot product between vectors $\\mathbf{u}$ and $\\mathbf{v}$.\n",
    "\n",
    "Consider the following cases:\n",
    "\n",
    "* $\\theta = 0$:\n",
    "In this case, $cos(\\theta) = 1 $, which means the two vectors are collinear. This is when $\\mathbf{u} \\; .  \\mathbf{v} = |\\mathbf{u}| \\; |\\mathbf{v}|$ has the maximum value.\n",
    "\n",
    "\n",
    "* $0 < \\theta < \\frac{\\pi}{2}$:\n",
    "In this case, $0 < cos(\\theta) < 1$, meaning that $|\\mathbf{u}| \\; |\\mathbf{v}|$ is multiplied by a number between 0 and 1, and it gets smaller. The wider the angle (or difference in direction) between the two vectors, the smaller the dot product gets.\n",
    "\n",
    "\n",
    "* $\\theta = \\frac{\\pi}{2}$:\n",
    "In this case, $cos(\\theta) = 0$, which means the two vectors are orthogonal. This is when $\\mathbf{u} \\; .  \\mathbf{v} = 0$.\n",
    "\n",
    "\n",
    "* $\\frac{\\pi}{2} < \\theta < \\pi $:\n",
    "In this case, $-1 < cos(\\theta) < 0$, meaning that $|\\mathbf{u}| \\; |\\mathbf{v}|$ is multiplied by a number between -1 and 0, and it gets smaller in absolute value, and negative. This means that the two vectors have started to point in very different directions. Again, the wider the angle between the two vectors, the smaller the dot product gets.\n",
    "\n",
    "\n",
    "* $\\theta = \\pi$:\n",
    "In this case, $cos(\\theta) = -1$, which means the two vectors are parallel, but pointing in opposite directions. This is when $\\mathbf{u} \\; .  \\mathbf{v} = -|\\mathbf{u}| \\; |\\mathbf{v}|$ has the minimum value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cosine distance (*)\n",
    "\n",
    "As we saw above, there is a relationship between the dot product and the cosine of two vectors:\n",
    "\n",
    "$$cos(\\theta) = \\frac{\\mathbf{u} \\; . \\mathbf{v}}{|\\mathbf{u}| \\; |\\mathbf{v}|}$$\n",
    "\n",
    "With the cosine, we are measuring how similar is the direction of the two vectors, and disregarding the vectors' norms.\n",
    "\n",
    "Now we just need to convert this similarity into a distance. Since the domain of the cosine function is $[-1, 1]$, we can do this in the following way:\n",
    "\n",
    "$$cos\\_dist(\\mathbf{u}, \\mathbf{v}) = 1 - cos(\\mathbf{u}, \\mathbf{v})$$\n",
    "\n",
    "The cosine distance works very well in cases where the features have values in different ranges. This is because dividing the dot product by the norms of the vectors works as a kind of normalization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(*) Note for the math nerds**\n",
    "\n",
    "Neither the dot product nor the cosine are distances, as per the mathematical definition of a [distance function](https://en.wikipedia.org/wiki/Distance#General_metric). Because of that, we cannot use some of scikit's optimisations that make kNN run faster. But that is a bit out of scope here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Some considerations about kNN\n",
    "\n",
    "Now that we have some intuition on how kNN works, and we've seen some functions that can be used as a distance (i.e, a measure of similarity), let's go through some considerations about this algorithm.\n",
    "\n",
    "\n",
    "### Non-parametric\n",
    "\n",
    "kNN is a non-parametric model because its structure is not specified a priori but is instead determined from the data.\n",
    "\n",
    "To better understand what this means, we can think of a counter example: Linear Regression, which is a parametric model, assumes that the data follows a linear distribution.\n",
    "\n",
    "\n",
    "### No learning\n",
    "\n",
    "When we described how does kNN work, you may have noticed a key difference between this algorithm and other algorithms that you've seen before, like Linear Regression or Logistic Regression: in kNN we don't actually learn anything!\n",
    "\n",
    "Taking Linear Regression as an example, in the traning phase, we used training data to learn some parameters ($\\beta$) that were later used in the prediction phase to make predictions on unseen data.\n",
    "\n",
    "In kNN we don't learn any parameters, and in the training phase we donÂ´t do more than just loading the training dataset into memory. Instead, most of the action takes place at prediction time, when we determine the nearest neighbours (using training data), and make predictions based on them. This is why we say that kNN is a **lazy** method.\n",
    "\n",
    "\n",
    "### How to chose the value of _k_\n",
    "\n",
    "The optimal choice of the value *k* is highly data-dependent: in general a larger _k_ suppresses the effects of noise, but making it too large results in more prediction errors.\n",
    "\n",
    "In `SLU18 - Hyperparameter Tuning`, we'll learn how to systematically find the best value for _k_.\n",
    "\n",
    "\n",
    "### kNN and high dimensional spaces\n",
    "\n",
    "When we increase the number of features in our model, we need more dimensions to represent the data points.\n",
    "\n",
    "The problem with high dimensional spaces is that the data gets very sparse, and consequently, points tend not to be close to each other. In particular, the k-nearest neighbours of a point won't be much closer to it than any other random points, which breaks the algorithm's assumption that points that are close are also similar.\n",
    "\n",
    "This phenomenon, called **curse of dimensionality**, is very well explained with an example [here](http://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html).\n",
    "\n",
    "This problem exists when we use the euclidean distance and the dot product, as these two distances measure amplitudes.\n",
    "The same doesn't happen with the cosine distance, that just considers directions.\n",
    "\n",
    "Another way to avoid this is to use dimensionality reduction techinques, in order to simplify our data. This won't be covered in this course.\n",
    "\n",
    "\n",
    "### kNN and large datasets\n",
    "\n",
    "Given a dataset with _N_ training points, when we try to get a prediction for a certain point, we need to load the entire dataset into memory and compute the distance between this point and all the other points.\n",
    "\n",
    "This means that the time that it takes to yield a prediction, depends on the dataset size. In fact, it grows linearly with it!\n",
    "\n",
    "Given these considerations, it's easy to understand that kNN is not the best choice when the dataset is very large.\n",
    "\n",
    "There are some ways to make kNN run faster, but these are out of the scope of this SLU!\n",
    "\n",
    "### Theoretically perfect\n",
    "\n",
    "K-nearest neighbors is a well-studied approach. There are many important theorems claiming that, on \"endless\" datasets, it is the optimal method of classification. \n",
    "\n",
    "The authors of the classic book \"The Elements of Statistical Learning\" consider k-NN to be a theoretically ideal algorithm which usage is only limited by computation power and the curse of dimensionality.\n",
    "\n",
    "### kNN in the real world\n",
    "\n",
    "kNN can serve as a good starting approach (baseline) in some cases.\n",
    "\n",
    "kNN might also be used in recommendation systems. The initial approach might be to recommend a product that is popular among K most similar people to a client.\n",
    "\n",
    "On Kaggle competitions, kNN is often used as a part of more complicated models that combine different approaches (those methods are called stacking and blending, but they are out of this course scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using kNN\n",
    "\n",
    "Let's now see how can we use kNN in classification and regression problems.\n",
    "\n",
    "Let's start with the usual imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Classification on the iris dataset\n",
    "\n",
    "We'll use kNN to solve the iris classification problem.\n",
    "\n",
    "The [iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) is a well known dataset for classification.\n",
    "\n",
    "In the dataset, each row (or observation) represents an iris flower. The features that describe the flower are _sepal length,_ _sepal width,_ _petal length_ and _petal width._\n",
    "\n",
    "The goal is to predict the iris' type, that can be one of _setosa,_ _versicolor_ and _virginica._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![iris](media/iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're doing a bunch of imports:\n",
    "\n",
    "* scikit's datasets: this is a package that allows up to load the iris dataset\n",
    "* accuracy score: this is to evaluate our classification model\n",
    "* train_test_split: this is to split out dataset into training and testing sets\n",
    "* **KNeighborsClassifier**: this is our kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the iris dataset and then split the dataset into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 100\n",
      "Test data size: 50\n"
     ]
    }
   ],
   "source": [
    "# Loading the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33, random_state=42)\n",
    "print(f\"Train data size: {len(X_train)}\\nTest data size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a DataFrame with the features and target in the training set, just to quickly check their values and check their ranges with a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.7               2.9                4.2               1.3   \n",
       "1                7.6               3.0                6.6               2.1   \n",
       "2                5.6               3.0                4.5               1.5   \n",
       "3                5.1               3.5                1.4               0.2   \n",
       "4                7.7               2.8                6.7               2.0   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       2  \n",
       "2       1  \n",
       "3       0  \n",
       "4       2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(X_train, columns=iris['feature_names'])\n",
    "df_train['target'] = y_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.boxplot(vert=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our goal is to predict labels for the data points in the testing set.\n",
    "\n",
    "First, let's get a baseline, which is the accuracy of the simplest model we can think of. Our model must be better than that!\n",
    "\n",
    "The simplest model is to always predict the most frequent class. So let's see how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = len(y_test)\n",
    "most_common_target = df_train.target.value_counts(sort=True).index[0]\n",
    "\n",
    "y_pred = np.ones(test_size) * most_common_target\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need to improve upon a 0.3 accuracy score. Let's see if we can do it with our kNN classifier.\n",
    "\n",
    "For each point in the testing set, kNN will search for the k nearest neighbours in the training set, and predict the most frequent label among the the neighbours.\n",
    "\n",
    "For now let's use the default value for k, which is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.98 accuracy! That's way better than our baseline. kNN did a good job :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Regression on the diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example with regression, we'll use the [diabetes dataset](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset).\n",
    "\n",
    "Each data point represents one person who has diabetes. The features have information like the person's age, sex, body mass index, and other health metrics. The target is a quantitative measure of disease progression one year after a certain baseline.\n",
    "\n",
    "Our goal is to predict this quantitative measure for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with some additional imports:\n",
    "\n",
    "* **KNeighborsRegressor**: this is our kNN regression model\n",
    "* mean_squared_error: this is to evaluate our model\n",
    "* scipy's cosine: this is for us to try the cosine distance in the kNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import cosine as cos_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did before, we'll load the dataset from scikit's datasets and then, do a train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 296\n",
      "Test data size: 146\n"
     ]
    }
   ],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.33, random_state=42)\n",
    "print(f\"Train data size: {len(X_train)}\\nTest data size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're loading the features into a DataFrame in order to quickly visualise them with the help of a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.030996</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.056619</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>0.084863</td>\n",
       "      <td>0.084495</td>\n",
       "      <td>0.048628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.005128</td>\n",
       "      <td>-0.064199</td>\n",
       "      <td>0.069981</td>\n",
       "      <td>0.083863</td>\n",
       "      <td>-0.039719</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0.019633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.009439</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.037517</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>0.050176</td>\n",
       "      <td>-0.025952</td>\n",
       "      <td>0.106617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>0.048477</td>\n",
       "      <td>-0.039719</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0.023775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.009016 -0.044642 -0.030996  0.021872  0.008063  0.008707  0.004460   \n",
       "1 -0.001882 -0.044642  0.054152 -0.066495  0.072732  0.056619 -0.043401   \n",
       "2  0.009016  0.050680 -0.005128 -0.064199  0.069981  0.083863 -0.039719   \n",
       "3  0.038076  0.050680 -0.009439  0.002363  0.001183  0.037517 -0.054446   \n",
       "4  0.027178  0.050680  0.025051  0.014987  0.025950  0.048477 -0.039719   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.009436  0.011349  \n",
       "1  0.084863  0.084495  0.048628  \n",
       "2  0.071210  0.039540  0.019633  \n",
       "3  0.050176 -0.025952  0.106617  \n",
       "4  0.034309  0.007837  0.023775  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train = pd.DataFrame(X_train, columns=diabetes['feature_names'])\n",
    "df_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_X_train.boxplot(vert=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's get a baseline. In this case, we'll always predict the mean value of the targets in the training set.\n",
    "\n",
    "We'll be using the mean_squared_error to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5755.467149460409"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline with predicting the average\n",
    "y_pred = np.ones(len(y_test)) * y_train.mean()\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the predictions using the kNN regressor. We'll use k=5, which is the default value, as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3224.3695890410954"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = KNeighborsRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a big improvement upon our baseline! Let's see if we can still do better, by chosing a different value for k.\n",
    "\n",
    "We'll learn how to do hyperparameter tuning properly in a later SLU, but for now let's go with this method.\n",
    "\n",
    "Plotting values of k vs the mean squared error will show us how does the error change with k. Then, we can select the value of k that minimises the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this list will save the different values for k and mean squared error\n",
    "k_rmse = []\n",
    "\n",
    "# for each value of k between 1 and 100, we'll compute the mean squared error\n",
    "# and save it in the k_rmse list like [(k1, error1), (k2, error2), ..., (k100, error100)]\n",
    "for k in range(1, 100):\n",
    "    reg = KNeighborsRegressor(k)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    k_rmse.append((k, mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# here we're separating the k values from the error values into two lists\n",
    "k_values, rmse_values = zip(*k_rmse)\n",
    "\n",
    "# and here we're plotting k vs the error\n",
    "plt.plot(k_values, rmse_values)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('mean squared error')\n",
    "plt.title('Mean squared error vs number of nearest neighbours (k)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that at first, the value of the error decreases a lot by adding more neighbours, and then we reach a point, around k=20, where by adding more neighbours we actually make the error worse!\n",
    "\n",
    "So let's stick to `k=20` and see what's our mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2979.621421232877"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = KNeighborsRegressor(n_neighbors=20)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still managed to improve a bit from our first attempt with k=5.\n",
    "\n",
    "Let's finish by checking how can we use the cosine distance instead of the euclidean distance (which is the default in scikit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2864.440273972603"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = KNeighborsRegressor(metric=cos_dist)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error decreases slightly, but not significantly.\n",
    "As we saw before, the cosine distance tends to work better than the euclidean distance when we have a lot of features (because of the curse of dimensionality) or when the features are within very different ranges.\n",
    "\n",
    "Neither of these two situations verifies here, so there is no great benefit in using the cosine distance.\n",
    "\n",
    "In fact, using the cosine distance is probably worse, as we'll not benefit from scikit's built in optimisations for kNN. If you try to find the best k in this scenario, using the method that we used above, you'll see that it will run much slower than with the euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
